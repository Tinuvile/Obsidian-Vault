
## 📊 监控指标集成全景

### **可观测性三大支柱**

在云原生环境中，运维团队需要**全方位了解系统状态**：

```
🔍 可观测性 = 指标(Metrics) + 日志(Logs) + 链路追踪(Traces)

┌─────────────────┐  ┌─────────────────┐  ┌─────────────────┐
│   📈 指标监控    │  │   📝 日志分析    │  │   🔗 链路追踪   │
│                 │  │                 │  │                 │
│ CPU/内存使用率   │  │ 错误日志          │  │ 请求调用链       │
│ QPS/延迟        │  │ 访问日志          │  │ 性能瓶颈         │
│ 集群状态         │  │ 系统事件          │  │ 依赖关系         │
└─────────────────┘  └─────────────────┘  └─────────────────┘
         ↓                    ↓                    ↓
    告警&自动化           故障排查&审计         性能优化&架构改进
```

### **RobustMQ监控需求**

**业务层监控**：
```
MQTT Broker指标：
├── 连接数统计 (当前连接、历史峰值)
├── 消息吞吐量 (发布/订阅 QPS)  
├── 主题订阅统计
├── 消息延迟分布
└── 错误率统计

Placement Center指标：
├── 集群节点状态
├── Leader选举次数
├── Raft日志同步延迟
└── 存储使用情况
```

**基础设施层监控**：
```
Kubernetes指标：
├── Pod资源使用 (CPU/内存/磁盘)
├── 容器重启次数
├── 网络流量统计
└── 存储IOPS统计
```

## 📈 1. Prometheus指标集成

### **RobustMQ现有指标基础分析**

从代码分析看，RobustMQ已经有相当完善的指标基础：

```rust
现有指标类型：
├── MQTT协议指标 (packets.rs)
│   ├── packets_received/sent (按网络类型分类)
│   ├── bytes_received/sent
│   └── 各种MQTT包类型统计
├── 性能指标 (placement-center)
│   ├── GRPC请求延迟和数量
│   ├── Raft存储操作性能
│   └── RocksDB存储操作
└── 系统指标
    ├── 运行时线程状态
    ├── 网络队列长度
    └── 客户端连接计数
```

## 📈 1. Prometheus指标增强

### **当前指标的云原生化改造**

**问题：现有指标缺少K8s标准标签**
```rust
// 现有标签结构
#[derive(EncodeLabelSet)]
pub struct NetworkLabel {
    pub network: String,  // 只有网络类型
}

// 缺少K8s环境信息：Pod名、命名空间、节点等
```

**解决方案：添加K8s标准标签**
```rust
// 增强的标签结构
#[derive(EncodeLabelSet)]
pub struct K8sAwareLabel {
    // 原有标签
    pub network: String,
    pub qos: String,
    
    // K8s标准标签
    pub pod_name: String,           // placement-center-0
    pub namespace: String,          // robustmq-production
    pub node_name: String,          // k8s-worker-1
    pub service_name: String,       // placement-center
    pub cluster_name: String,       // robustmq-cluster-prod
    pub version: String,            // 0.3.0
}

impl K8sAwareLabel {
    pub fn from_env() -> Self {
        Self {
            pod_name: std::env::var("HOSTNAME")
                .unwrap_or_else(|_| "unknown-pod".to_string()),
            namespace: std::env::var("POD_NAMESPACE")
                .unwrap_or_else(|_| "default".to_string()),
            node_name: std::env::var("NODE_NAME")
                .unwrap_or_else(|_| "unknown-node".to_string()),
            service_name: std::env::var("SERVICE_NAME")
                .unwrap_or_else(|_| "robustmq".to_string()),
            cluster_name: std::env::var("CLUSTER_NAME")
                .unwrap_or_else(|_| "robustmq-cluster".to_string()),
            version: std::env::var("APP_VERSION")
                .unwrap_or_else(|_| "unknown".to_string()),
            // ... 其他字段
        }
    }
}
```

**在K8s部署中注入环境变量**：
```yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: placement-center
spec:
  template:
    spec:
      containers:
      - name: placement-center
        env:
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: POD_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: NODE_NAME
          valueFrom:
            fieldRef:
              fieldPath: spec.nodeName
        - name: SERVICE_NAME
          value: "placement-center"
        - name: CLUSTER_NAME
          value: "robustmq-cluster"
        - name: APP_VERSION
          value: "0.3.0"
```

### **添加业务关键指标**

```rust
// 集群健康指标
common_base::register_gauge_metric!(
    CLUSTER_LEADER_STATUS,
    "robustmq_cluster_leader_status",
    "Is this node the cluster leader (1=leader, 0=follower)",
    K8sAwareLabel
);

common_base::register_gauge_metric!(
    CLUSTER_NODE_COUNT,
    "robustmq_cluster_nodes_total",
    "Total number of nodes in the cluster",
    K8sAwareLabel
);

// MQTT业务指标
common_base::register_histogram_metric!(
    MESSAGE_LATENCY,
    "robustmq_message_latency_seconds",
    "Message processing latency distribution",
    K8sAwareLabel,
    [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0, 5.0]
);

common_base::register_gauge_metric!(
    ACTIVE_CONNECTIONS,
    "robustmq_connections_active",
    "Number of active MQTT connections",
    K8sAwareLabel
);

// 存储健康指标
common_base::register_gauge_metric!(
    STORAGE_DISK_USAGE_BYTES,
    "robustmq_storage_disk_usage_bytes",
    "Disk usage in bytes",
    K8sAwareLabel
);
```

### **ServiceMonitor集成**

```yaml
# monitoring/servicemonitor.yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: robustmq-metrics
  labels:
    app: robustmq
spec:
  selector:
    matchLabels:
      app: robustmq
  endpoints:
  - port: metrics          # Service中定义的指标端口
    path: /metrics
    interval: 30s
    scrapeTimeout: 10s
    relabelings:
    - sourceLabels: [__meta_kubernetes_pod_name]
      targetLabel: pod
    - sourceLabels: [__meta_kubernetes_namespace]
      targetLabel: namespace
```

## 📊 2. Grafana仪表板设计

### **多层次仪表板架构**

**1. 集群概览仪表板**
```json
{
  "dashboard": {
    "title": "RobustMQ Cluster Overview",
    "panels": [
      {
        "title": "Cluster Health",
        "type": "stat",
        "query": "robustmq_cluster_nodes_total",
        "thresholds": [
          {"color": "red", "value": 0},
          {"color": "yellow", "value": 1}, 
          {"color": "green", "value": 3}
        ]
      },
      {
        "title": "Message Throughput",
        "type": "graph",
        "query": "rate(robustmq_packets_publish_received[5m])",
        "legend": "{{pod}} - {{namespace}}"
      },
      {
        "title": "Active Connections",
        "type": "graph",
        "query": "robustmq_connections_active",
        "legend": "{{service_name}}"
      }
    ]
  }
}
```

**2. MQTT Broker详细仪表板**
```json
{
  "dashboard": {
    "title": "RobustMQ MQTT Broker Details", 
    "panels": [
      {
        "title": "Message Latency P99",
        "type": "graph",
        "query": "histogram_quantile(0.99, robustmq_message_latency_seconds)",
        "alert": {
          "condition": "gt 1.0",
          "message": "High message latency detected"
        }
      },
      {
        "title": "Connection Rate",
        "type": "graph", 
        "query": "rate(robustmq_packets_connect_received[1m])"
      },
      {
        "title": "Error Rate",
        "type": "stat",
        "query": "rate(robustmq_packets_received_error[5m])",
        "thresholds": [
          {"color": "green", "value": 0},
          {"color": "yellow", "value": 0.01},
          {"color": "red", "value": 0.05}
        ]
      }
    ]
  }
}
```

**3. Placement Center仪表板**
```json
{
  "dashboard": {
    "title": "RobustMQ Placement Center",
    "panels": [
      {
        "title": "Leader Election",
        "type": "graph",
        "query": "robustmq_cluster_leader_status",
        "legend": "{{pod_name}}"
      },
      {
        "title": "Raft Log Replication Latency", 
        "type": "graph",
        "query": "robustmq_raft_storage_total_ms"
      },
      {
        "title": "Storage Disk Usage",
        "type": "gauge",
        "query": "robustmq_storage_disk_usage_bytes"
      }
    ]
  }
}
```

### **仪表板配置管理**

```yaml
# grafana/dashboards-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: robustmq-dashboards
  labels:
    grafana_dashboard: "1"    # Grafana自动发现标签
data:
  cluster-overview.json: |
    {{ .Files.Get "dashboards/cluster-overview.json" | indent 4 }}
  mqtt-broker.json: |
    {{ .Files.Get "dashboards/mqtt-broker.json" | indent 4 }}
  placement-center.json: |
    {{ .Files.Get "dashboards/placement-center.json" | indent 4 }}
```

## 📝 3. 日志聚合 (Fluent Bit集成)

### **日志标准化改造**

**当前问题：日志格式不统一**
```rust
// 现有日志格式混乱
info!("Connection established: {}", client_id);
error!("Failed to process message");
debug!("Raft log entry: {:?}", entry);
```

**解决方案：结构化日志**
```rust
use tracing::{info, error, debug, instrument};
use serde_json::json;

// 统一的日志结构
#[derive(serde::Serialize)]
struct LogEvent {
    level: String,
    message: String,
    component: String,
    client_id: Option<String>,
    topic: Option<String>,
    trace_id: Option<String>,
    #[serde(flatten)]
    extra: serde_json::Value,
}

// 使用结构化日志
pub fn log_connection_event(client_id: &str, event_type: &str, success: bool) {
    info!(
        target: "mqtt.connection",
        client_id = %client_id,
        event_type = %event_type, 
        success = %success,
        component = "mqtt-broker",
        "MQTT connection event"
    );
}

pub fn log_message_processing(topic: &str, qos: u8, latency_ms: f64) {
    info!(
        target: "mqtt.message",
        topic = %topic,
        qos = %qos,
        latency_ms = %latency_ms,
        component = "mqtt-broker",
        "Message processed successfully"
    );
}
```

### **Fluent Bit配置**

```yaml
# fluent-bit-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: fluent-bit-config
data:
  fluent-bit.conf: |
    [SERVICE]
        Flush         1
        Log_Level     info
        Daemon        off
        Parsers_File  parsers.conf
        HTTP_Server   On
        HTTP_Listen   0.0.0.0
        HTTP_Port     2020

    [INPUT]
        Name              tail
        Path              /var/log/containers/robustmq-*_*.log
        Parser            docker
        Tag               robustmq.*
        Refresh_Interval  5
        Mem_Buf_Limit     50MB

    [FILTER]
        Name                kubernetes
        Match               robustmq.*
        Kube_URL            https://kubernetes.default.svc:443
        Kube_CA_File        /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        Kube_Token_File     /var/run/secrets/kubernetes.io/serviceaccount/token
        Merge_Log           On
        K8S-Logging.Parser  On
        K8S-Logging.Exclude Off

    [FILTER]
        Name    grep
        Match   robustmq.*
        Regex   log_level (INFO|WARN|ERROR)

    [OUTPUT]
        Name  es
        Match robustmq.*
        Host  elasticsearch.monitoring.svc.cluster.local
        Port  9200
        Index robustmq-logs
        Type  _doc

  parsers.conf: |
    [PARSER]
        Name        docker
        Format      json
        Time_Key    time
        Time_Format %Y-%m-%dT%H:%M:%S.%L
        Time_Keep   On

    [PARSER]
        Name        robustmq
        Format      regex
        Regex       ^(?<time>\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}\.\d{3}Z)\s+(?<level>\w+)\s+(?<component>\w+):\s+(?<message>.*)$
        Time_Key    time
        Time_Format %Y-%m-%dT%H:%M:%S.%LZ
```

### **日志查询和告警**

```json
// Elasticsearch查询示例
{
  "query": {
    "bool": {
      "must": [
        {"term": {"kubernetes.labels.app": "robustmq"}},
        {"term": {"level": "ERROR"}},
        {"range": {"@timestamp": {"gte": "now-1h"}}}
      ]
    }
  },
  "aggs": {
    "errors_by_component": {
      "terms": {"field": "component.keyword"}
    }
  }
}
```

## 🔗 4. 链路追踪 (OpenTelemetry)

### **分布式追踪架构**

```
客户端发布消息的完整链路：
┌──────────────┐    ┌──────────────┐    ┌──────────────┐
│ MQTT Client  │───▶│ MQTT Broker  │───▶│Placement Ctr │
│              │    │              │    │              │
│ publish()    │    │ receive()    │    │ store_meta() │
│ trace_id:123 │    │ trace_id:123 │    │ trace_id:123 │
└──────────────┘    └──────────────┘    └──────────────┘
                             │
                             ▼
                    ┌──────────────┐
                    │Journal Server│
                    │              │
                    │ persist()    │
                    │ trace_id:123 │
                    └──────────────┘
```

### **OpenTelemetry集成实现**

```rust
// Cargo.toml
[dependencies]
opentelemetry = "0.21"
opentelemetry-jaeger = "0.20"
tracing-opentelemetry = "0.22"
tracing-subscriber = "0.3"

// trace.rs
use opentelemetry::{global, trace::TraceContextExt, Context, KeyValue};
use opentelemetry_jaeger::new_agent_pipeline;
use tracing_opentelemetry::OpenTelemetryLayer;
use tracing_subscriber::{layer::SubscriberExt, Registry};

pub fn init_tracing(service_name: &str) -> Result<(), Box<dyn std::error::Error>> {
    // 初始化Jaeger tracer
    let tracer = new_agent_pipeline()
        .with_service_name(service_name)
        .with_endpoint("http://jaeger-agent.monitoring.svc.cluster.local:14268/api/traces")
        .install_batch(opentelemetry::runtime::Tokio)?;
    
    // 配置tracing subscriber
    let subscriber = Registry::default()
        .with(OpenTelemetryLayer::new(tracer))
        .with(tracing_subscriber::fmt::layer());
    
    tracing::subscriber::set_global_default(subscriber)?;
    Ok(())
}

// 在应用启动时初始化
#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    init_tracing("robustmq-mqtt-broker")?;
    
    // 应用逻辑...
    Ok(())
}
```

### **关键路径追踪实现**

```rust
use tracing::{instrument, info_span, Instrument};
use opentelemetry::trace::{Span, Tracer};

// MQTT消息处理链路追踪
#[instrument(
    name = "mqtt.publish.handle",
    fields(
        client_id = %client_id,
        topic = %topic,
        qos = %qos,
    )
)]
pub async fn handle_publish_message(
    client_id: &str,
    topic: &str, 
    payload: &[u8],
    qos: u8,
) -> Result<(), MqttError> {
    // 创建span
    let span = info_span!("mqtt.message.receive");
    
    // 消息验证
    validate_message(topic, payload).instrument(span.clone()).await?;
    
    // 存储到placement-center
    let storage_span = info_span!("placement_center.store", 
        operation = "store_message_metadata"
    );
    store_message_metadata(client_id, topic)
        .instrument(storage_span)
        .await?;
    
    // 持久化到journal
    let persist_span = info_span!("journal.persist",
        operation = "write_message"
    );
    persist_message(payload)
        .instrument(persist_span)
        .await?;
    
    // 分发给订阅者
    let deliver_span = info_span!("mqtt.deliver",
        operation = "fanout_message"
    );
    deliver_to_subscribers(topic, payload)
        .instrument(deliver_span)
        .await?;
    
    Ok(())
}

// 跨服务调用传播trace context
pub async fn call_placement_center(
    request: PlacementRequest
) -> Result<PlacementResponse, GrpcError> {
    let mut client = self.grpc_client.clone();
    
    // 提取当前trace context
    let context = Context::current();
    let span_context = context.span().span_context();
    
    // 在gRPC metadata中传播trace ID
    let mut metadata = tonic::metadata::MetadataMap::new();
    metadata.insert(
        "trace-id",
        span_context.trace_id().to_string().parse().unwrap()
    );
    metadata.insert(
        "span-id", 
        span_context.span_id().to_string().parse().unwrap()
    );
    
    let mut request = tonic::Request::new(request);
    *request.metadata_mut() = metadata;
    
    client.store_metadata(request).await
}
```

### **Jaeger部署配置**

```yaml
# jaeger.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: jaeger
spec:
  replicas: 1
  selector:
    matchLabels:
      app: jaeger
  template:
    spec:
      containers:
      - name: jaeger
        image: jaegertracing/all-in-one:1.50
        env:
        - name: COLLECTOR_ZIPKIN_HOST_PORT
          value: ":9411"
        - name: SPAN_STORAGE_TYPE
          value: elasticsearch
        - name: ES_SERVER_URLS
          value: http://elasticsearch.monitoring.svc.cluster.local:9200
        ports:
        - containerPort: 16686  # Jaeger UI
        - containerPort: 14268  # Jaeger collector
---
apiVersion: v1
kind: Service
metadata:
  name: jaeger
spec:
  ports:
  - port: 16686
    name: ui
  - port: 14268
    name: collector
  selector:
    app: jaeger
```

## 🚨 5. 告警和自动化

### **Prometheus告警规则**

```yaml
# alerts.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: robustmq-alerts
spec:
  groups:
  - name: robustmq.cluster
    rules:
    - alert: RobustMQClusterDown
      expr: robustmq_cluster_nodes_total < 2
      for: 1m
      labels:
        severity: critical
      annotations:
        summary: "RobustMQ cluster has insufficient nodes"
        description: "Only {{ $value }} nodes available, minimum 2 required"
        
    - alert: RobustMQHighLatency
      expr: histogram_quantile(0.99, robustmq_message_latency_seconds) > 1.0
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "High message processing latency"
        description: "P99 latency is {{ $value }}s"
        
    - alert: RobustMQHighErrorRate
      expr: rate(robustmq_packets_received_error[5m]) > 0.05
      for: 2m
      labels:
        severity: critical
      annotations:
        summary: "High error rate detected"
        description: "Error rate: {{ $value | humanizePercentage }}"
```

这个全面的监控集成方案将为RobustMQ提供生产级的可观测性能力，帮助运维团队快速发现和解决问题。
