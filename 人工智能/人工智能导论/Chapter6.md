### **《卷积神经网络（CNN）原理与应用》PPT内容详解**

---

#### **一、案例研究：CIFAR-10图像分类**
##### **1. CIFAR-10数据集**
- **数据规模**：60,000张彩色图像，分为10个类别（飞机、汽车、鸟、猫等），每类6,000张。  
- **图像规格**：32×32像素，RGB三通道（3×32×32张量）。  
- **任务目标**：输入图像，输出其所属类别标签（10选1分类）。

##### **2. 全连接网络的局限性**
- **输入维度**：32×32×3=3,072维向量。  
- **参数量问题**：若首层全连接输出1,000个神经元，参数量为3,072×1,000=3,072,000，易导致过拟合。  
- **空间信息丢失**：将图像展平为向量，忽略局部结构和空间相关性。

---

#### **二、CNN核心思想与图像特性适配**
##### **1. 局部相关性（Local Connectivity）**
- **感受野（Receptive Field）**：  
  - 每个神经元仅连接输入图像的局部区域（如3×3窗口），而非全图。  
  - **优势**：捕捉边缘、纹理等局部特征，减少参数量。  
  - **示例**：首层卷积核检测边缘，深层组合成复杂形状（如眼睛、车轮）。

##### **2. 非局部相似性（Parameter Sharing）**
- **参数共享**：同一卷积核在图像不同位置滑动，提取相同特征。  
  - **数学表达**：  
    $$
    (I * K)_{i,j} = \sum_{m=0}^{k_h-1} \sum_{n=0}^{k_w-1} K_{m,n} \cdot I_{i+m, j+n}
    $$
    其中 $K$ 为卷积核，$I$ 为输入图像。  
  - **优势**：显著降低参数量，例如3×3卷积核仅需9个参数（不计偏置）。

##### **3. 缩放不变性（Pooling）**
- **池化操作**：降采样保留主要特征，增强平移/缩放鲁棒性。  
  - **最大池化（Max Pooling）**：取窗口内最大值，突出显著特征。  
  - **平均池化（Mean Pooling）**：取窗口内均值，平滑噪声。  
  - **效果**：减少空间尺寸（如4×4→2×2），提升计算效率。

---

#### **三、卷积层的数学与实现细节**
##### **1. 卷积操作**
- **输入输出关系**：  
  - **输入**：$C_{\text{in}} \times H_{\text{in}} \times W_{\text{in}}$（通道×高×宽）。  
  - **卷积核**：$C_{\text{out}} \times C_{\text{in}} \times k_h \times k_w$（输出通道×输入通道×核高×核宽）。  
  - **输出**：$C_{\text{out}} \times H_{\text{out}} \times W_{\text{out}}$，其中：  
    $$
    H_{\text{out}} = \left\lfloor \frac{H_{\text{in}} + 2p - k_h}{s} \right\rfloor + 1
    $$
    $p$ 为填充（padding），$s$ 为步长（stride）。

##### **2. 多通道卷积**
- **RGB图像处理**：每个卷积核同时处理所有输入通道，输出单通道特征图。  
  - **示例**：输入3通道（RGB），卷积核尺寸3×3×3，输出1通道特征图。  
  - **多核堆叠**：使用多个卷积核生成多通道特征图（如64个核→64通道）。

##### **3. 填充与步长**
- **填充（Padding）**：在输入边缘补零，控制输出尺寸。  
  - **Same Padding**：填充使输出尺寸与输入相同（需 $p = \frac{k-1}{2}$）。  
- **步长（Stride）**：卷积核移动步长，影响输出尺寸和计算量。  
  - **示例**：输入7×7，卷积核3×3，步长2→输出3×3。

---

#### **四、CNN架构设计**
##### **1. 典型CNN结构**

>[!info] 结构
>输入图像 → [卷积层 → 激活函数[[人工智能/人工智能导论/Chapter4#^5a7ba8|Chapter4]] → 池化层] × N → 展平 → 全连接层 → Softmax输出

- **经典网络**：  
  - **LeNet-5**：早期手写数字识别（卷积+池化+全连接）。  
  - **AlexNet**：引入ReLU和Dropout，ImageNet竞赛突破。  
  - **VGGNet**：深层小卷积核（3×3），统一模块化设计。

##### **2. 感受野计算**
- **叠加卷积层**：  
  - 两层3×3卷积等效于一层5×5卷积的感受野。  
  - **公式**：$RF_{\text{new}} = RF_{\text{prev}} + (k - 1) \times \prod s_i$。  
  - **示例**：首层3×3（RF=3），第二层3×3（步长1）→ RF=5。

##### **3. 池化层作用**
- **降维**：减少参数和计算量（如32×32→16×16）。  
- **平移不变性**：轻微平移不影响分类结果。  
- **防止过拟合**：抑制噪声，增强泛化能力。

---

#### **五、CNN应用场景**
##### **1. 图像分类**
- **案例**：CIFAR-10、ImageNet。  
- **性能**：ResNet-50在ImageNet上Top-1准确率76%。

##### **2. 目标检测**
- **模型**：Faster R-CNN、YOLO。  
- **机制**：区域提议（Region Proposal） + 分类回归。

##### **3. 语义分割**
- **模型**：U-Net、DeepLab。  
- **特点**：像素级分类，输出掩膜（Mask）。

##### **4. 其他领域**
- **医学影像**：肿瘤检测、X光分类。  
- **视频分析**：行为识别、运动追踪。

---

#### **六、代码示例（PyTorch实现CNN）**
```python
import torch.nn as nn

class CNN(nn.Module):
    def __init__(self):
        super(CNN, self).__init__()
        self.conv_layers = nn.Sequential(
            # 输入: 3x32x32 (CIFAR-10)
            nn.Conv2d(3, 64, 3, padding=1),  # 输出: 64x32x32
            nn.ReLU(),
            nn.MaxPool2d(2),                  # 输出: 64x16x16
            nn.Conv2d(64, 128, 3, padding=1), # 输出: 128x16x16
            nn.ReLU(),
            nn.MaxPool2d(2)                   # 输出: 128x8x8
        )
        self.fc_layers = nn.Sequential(
            nn.Flatten(),
            nn.Linear(128 * 8 * 8, 1024),
            nn.ReLU(),
            nn.Linear(1024, 10)
        )

    def forward(self, x):
        x = self.conv_layers(x)
        x = self.fc_layers(x)
        return x
```

---

#### **七、总结**
- **核心优势**：局部感知、参数共享、平移不变性。  
- **设计要点**：堆叠卷积-池化模块，逐步扩大感受野，末端全连接分类。  
- **应用价值**：从图像分类到自动驾驶，CNN是计算机视觉的基石模型。