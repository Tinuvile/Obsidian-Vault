伪代码的标准格式：

```text
Algorithm Euclid(m,n)
// Computes gcd(m,n) by Euclid's algorithm
// Input:Two nonnegative,not-both-zero integers m and n
// Output:Greatest common divisor of m and n
while n≠0 do
   r <- m mod n
   m <- n
   n <- r
return m
```

- 省略变量的声明
- 使用缩进显示`for`、`if`和`while`等语句的范围
- 使用箭头进行分配

---

# 算法效率分析原理

时间利用效率$T(N,I)$，空间利用效率$S(N,I)$，$C=F(N,I,A)$描述了算法效率与输入规模$N$、输入类型$I$和算法功能$A$的关系。

---

## 时间效率的理论分析

通过确定基本操作（通常是算法中最耗时、对总运行时间贡献最大的操作，常见于最内层循环）的重复次数作为输入规模的函数。
$$
T(n)≈t_{op}​⋅C(n)
$$
- $T(n)$：算法对规模为 $n$ 的输入的**总运行时间（running time）**，即算法执行完所需的实际时间。
- $t_{op}$​：**单个基本操作的执行时间（execution time for the basic operation）**，比如一次比较、一次赋值的耗时（与硬件、编程语言等相关，分析时可视为常数）。
- $C(n)$：**基本操作的执行次数（Number of times the basic operation is executed）**，随输入规模 $n$ 变化的函数（比如遍历数组找最大值，$C(n)$ 就是数组长度 $n$ ）。
- **输入规模（input size）**：决定算法处理的数据量，是影响运行时间的根本因素（比如排序 10 个数据 vs 排序 1000 个数据，输入规模 $n$ 不同，运行时间差异大）。
- **基本操作执行次数 $C(n)$**：由算法逻辑和输入规模共同决定，是 “算法本身效率” 的核心体现（同样输入规模，不同算法的 $C(n)$ 可能天差地别，比如冒泡排序 vs 快速排序）。
- **单个基本操作时间 $t_{op​}$**：受硬件性能（CPU 速度、内存带宽等）、编程语言、编译器优化等 “外部因素” 影响，**分析算法本身效率时，常默认 $t_{op}$​ 为常数**（因为我们关注的是 “算法逻辑” 对运行时间的影响，而非硬件 / 语言的差异）。

| $n$      | $\log_{2} n$ | $n$      | $n \log_{2} n$     | $n^{2}$   | $n^{3}$   | $2^{n}$             | $n!$                 |
| -------- | ------------ | -------- | ------------------ | --------- | --------- | ------------------- | -------------------- |
| $10$     | $3.3$        | $10^{1}$ | $3.3 \cdot 10^{1}$ | $10^{2}$  | $10^{3}$  | $10^{3}$            | $3.6 \cdot 10^{6}$   |
| $10^{2}$ | $6.6$        | $10^{2}$ | $6.6 \cdot 10^{2}$ | $10^{4}$  | $10^{6}$  | $1.3 \cdot 10^{30}$ | $9.3 \cdot 10^{157}$ |
| $10^{3}$ | $10$         | $10^{3}$ | $1.0 \cdot 10^{4}$ | $10^{6}$  | $10^{9}$  |                     |                      |
| $10^{4}$ | $13$         | $10^{4}$ | $1.3 \cdot 10^{5}$ | $10^{8}$  | $10^{12}$ |                     |                      |
| $10^{5}$ | $17$         | $10^{5}$ | $1.7 \cdot 10^{6}$ | $10^{10}$ | $10^{15}$ |                     |                      |
| $10^{6}$ | $20$         | $10^{6}$ | $2.0 \cdot 10^{7}$ | $10^{12}$ | $10^{18}$ |                     |                      |

**算法平均效率的计算：**
$$
T_{avg }(N)=\sum_{I \in D_{N}} P(I) T(N, I)=\sum_{I \in D_{N}} P(I) \sum_{i=1}^{k} t_{i} e_{i}(N, I)
$$
- **$T_{avg}​(N)$**：算法对规模为 $N$ 的输入的**平均情况运行时间**。
- $D_N​$：规模为 $N$ 的**所有可能输入的集合**（比如排序算法中，长度为 N 的数组的所有排列组合 ）。
- $P(I)$：输入 $I∈D_N​$ 出现的**概率**（需满足 $∑I∈D_N​​P(I)=1$，即所有输入概率和为 1 ）。
- $T(N,I)$：算法在输入 $I$（规模 $N$ ）下的**实际运行时间**。
- $ti​$：第 $i$ 种**基本操作的单次执行时间**（比如一次比较、一次赋值的耗时，分析时可视为常数 ）。
- $e_i​(N,I)$：算法在输入 $I$（规模 $N$ ）下，第 $i$ 种**基本操作的执行次数**。

---

## 渐进复杂性

当输入规模 $n \to \infty$ 时，若算法的时间/空间开销 $T(n)$ 满足：  
$$
T(n) \approx t_{\text{op}} \cdot C(n)
$$
$( t_{\text{op}}$ 是基本操作耗时，$C(n)$ 是基本操作执行次数）  
**渐近复杂度聚焦 $C(n)$ 的“增长阶”**（如 $O(n^2)$、$\Theta(n \log n)$ ），而非具体运行时间，以此剥离硬件、编程语言等“环境因素”，纯粹比较算法逻辑的效率。 

### 常用渐近符号  
- **$O(g(n))$**（上界）：若存在常数 $c>0$ 和 $n_0$，当 $n \geq n_0$ 时，$T(n) \leq c \cdot g(n)$，则 $T(n)$ 的渐近上界是 $O(g(n))$。例如冒泡排序的时间复杂度是 $O(n^2)$，表示其运行时间不会超过 $n^2$ 的某个倍数。  
- **$\Omega(g(n))$**（下界）：若存在常数 $c>0$ 和 $n_0$，当 $n \geq n_0$ 时，$T(n) \geq c \cdot g(n)$，则 $T(n)$ 的渐近下界是 $\Omega(g(n))$。例如任何基于比较的排序算法，时间复杂度下界是 $\Omega(n \log n)$，表示其再快也不可能低于 $n \log n$ 的增长趋势。  
- **$\Theta(g(n))$**（紧界）：若 $T(n)$ 同时满足 $O(g(n))$ 和 $\Omega(g(n))$，则 $T(n)$ 是 $\Theta(g(n))$，表示算法运行时间“恰好”以 $g(n)$ 的速度增长（如归并排序的时间复杂度是 $\Theta(n \log n)$ ）。  

### 使用极限比较增长阶数
$$
\lim_{n\rightarrow\infty}\frac{T(n)}{g(n)} = \begin{cases} 0, & \text{order of growth of } T(n) < \text{order of growth of } g(n) \\ c>0, & \text{order of growth of } T(n) = \text{order of growth of } g(n) \\ \infty, & \text{order of growth of } T(n) > \text{order of growth of } g(n) \end{cases}
$$

1. **对数函数**：所有对数函数$\log_{a}n$（$a>1$）都属于同一类$\Theta(\log n)$。无论对数的底数$a$是多少，当输入规模$n$变化时，它们的增长速度在渐近意义上是相同的。
2. **多项式函数**：所有相同次数$k$的多项式属于同一类，即$a_{k}n^{k}+a_{k - 1}n^{k - 1}+\cdots +a_{0} \in \Theta(n^{k})$。例如，对于二次多项式$3n^{2}+2n + 1$，其渐近复杂度为$\Theta(n^{2})$。随着$n$的增大，多项式中次数最高的项起主导作用，决定了函数的增长速度。
3. **指数函数**：指数函数$a^{n}$，不同的$a$值会导致不同的增长速度。指数函数增长速度极快，当$a>1$时，随着$n$的增加，函数值会迅速增大。
4. **函数增长阶比较**：按照增长阶从小到大排序为：$\log n < n^{\epsilon}(a>0) < a^{n} < n! < n^{n}$。

---

## 非递归算法的时间效率
1. 确定输入规模$n$
2. 识别算法的基本操作
3. 检查基本操作的执行次数是否仅依赖于输入规模$n$，若还与输入类型相关，则需分别研究最坏情况、平均情况和最佳情况的效率
4. 建立关于$C(n)$的求和表达式，反映算法基本操作的执行次数
5. 使用标准公式简化求和式，以找到闭式表达式，或确定增长阶数
### 例题：

> [!example] Maximum element
> ``` text
> MaxElement(A(0.n-1)
> //Determines the value of the largest element in a given array 
> //Input: An array A[0..n - 1]of real numbers 
> //Output: The value of the largest element in A 
> maxval ←-A[0] 
> for i<-1 to n-1 do
>    if A[i]> maxval 
>        maxval <= A[i]
> return maxval
> ```
> 基本操作：比较大小`if A[i]> maxval`
> 输入大小：数组长度`n`
> 时间效率：$C(n)=\sum_{i=1}^{n-1} 1=n-1=\Theta(n)$

> [!example] Element uniqueness problem
> ```
> Unique ElementsA([0..n-1])
> //Determines whether all the elements in a given array are distinct 
> //Input: An array A[0..n-1]
> //Output: Returns "true"'if a the elements in A are distinct
> // and "false"otherwise 
> for i-0 to n-2 do
>    for j←i+1 to n-1 do
>     if A[i]= A[j] return false 
> return true
> ```
> 基本操作：比较
> 输入大小：数组长度$n$
> 时间复杂度：比较取决于数组大小和是否有相等元素以及它们的位置
> 最坏情况：
> $$\begin{align*} C_{\text{worst}}(n) & =\sum_{i=0}^{n-2} \sum_{j=i+1}^{n-1} 1=\sum_{i=0}^{n-2}[(n-1)-(i+1)+1]=\sum_{i=0}^{n-2}(n-i-1) \\ & =\sum_{i=0}^{n-2}(n-1)-\sum_{i=0}^{n-2} i=(n-1) \sum_{i=0}^{n-2} 1-\sum_{i=0}^{n-2} i=(n-1)^{2}-\frac{(n-2)(n-1)}{2} \\ & =\frac{n(n-1)}{2} \in \Theta\left(n^{2}\right) \end{align*}$$

> [!todo] Matrix multiplication
> ```
> MatrixMultiplication(A[0..n-1,0..n-1], B[0..n-1,0..n-1])
> //Multiplies two n-by-n matrices by the definition-based algorithm 
> //Input: Two n-by-n matrices A and B
> //Output: Matrix C = AB
> for i←0 to n-1 do
>    for j←0 to n-1 do
>       C[i,j]←0.0
>       for k←0 to n-1 do
>          C[i,j]←C[i,j] + A[i,k] * B[k,j]
> return C
> ```
> 基本操作：乘法  
> 输入大小：矩阵阶数$n$  
> 时间复杂度：取决于矩阵阶数$n$  
> 最坏情况：  
> $$\begin{align*} C(n) & = n \cdot n \cdot n = n^3 \in O(n^3) \end{align*}$$

> [!todo] Counting binary digits  
> ```  
> Binary(n)  
> //Input: A positive decimal integer n  
> //Output: The number of binary digits in n's binary representation  
> count←1  
> while n > 1 do  
>    count←count + 1  
>    n←⌊n/2⌋  
> return count  
> ```  
> 基本操作：循环迭代（每次除法和计数）  
> 输入大小：十进制整数$n$  
> 时间复杂度：与$n$的二进制位数相关  
> 关键分析：  
> - 循环次数等于$n$的二进制位数减1（如$n=8$（二进制 `1000`）时，循环执行 3 次）。  
> - 二进制位数为$\lfloor \log_2 n \rfloor + 1$，故时间复杂度为$\Theta(\log n)$。

---

## 递归算法的分析步骤


